{
  "date": "2026-02-01",
  "generated_at": "2026-02-01T20:55:54.739286+00:00",
  "categories": [
    "cs.AI",
    "cs.CL",
    "cs.LG"
  ],
  "interests": "machine learning, AI agents, large language models\n\nWhen ranking, also consider:\n- Author credentials and reputation (prefer established researchers from top institutions)\n- Quality of methodology described in abstract\n- Novelty and potential impact of the work\n- Papers with well-known authors in the field should be scored higher",
  "total_papers_fetched": 100,
  "papers": [
    {
      "arxiv_id": "2304.07297",
      "title": "Language Instructed Reinforcement Learning for Human-AI Coordination",
      "abstract": "One of the fundamental quests of AI is to produce agents that coordinate well with humans. This problem is challenging, especially in domains that lack high quality human behavioral data, because multi-agent reinforcement learning (RL) often converges to different equilibria from the ones that humans prefer. We propose a novel framework, instructRL, that enables humans to specify what kind of strategies they expect from their AI partners through natural language instructions. We use pretrained large language models to generate a prior policy conditioned on the human instruction and use the prior to regularize the RL objective. This leads to the RL agent converging to equilibria that are aligned with human preferences. We show that instructRL converges to human-like policies that satisfy the given instructions in a proof-of-concept environment as well as the challenging Hanabi benchmark. Finally, we show that knowing the language instruction significantly boosts human-AI coordination performance in human evaluations in Hanabi.",
      "authors": [],
      "categories": [
        "Computer Science"
      ],
      "published": "2023-01-01",
      "updated": "2023-01-01",
      "link": "https://www.semanticscholar.org/paper/bd05f81167ca3f77460f4a1da3bf5ade9febb15b",
      "relevance_score": 9.0,
      "relevance_reason": "The paper directly addresses the interests of machine learning, AI agents, and large language models. The methodology described in the abstract is novel and has potential impact in improving human-AI coordination. The use of pretrained large language models and natural language instructions adds to the relevance of this paper.",
      "author_h_indices": [
        16,
        64
      ],
      "huggingface_upvotes": null,
      "quality_score": 9.36734693877551
    },
    {
      "arxiv_id": "2402.05119",
      "title": "A Closer Look at the Limitations of Instruction Tuning",
      "abstract": "Instruction Tuning (IT), the process of training large language models (LLMs) using instruction-response pairs, has emerged as the predominant method for transforming base pre-trained LLMs into open-domain conversational agents. While IT has achieved notable success and widespread adoption, its limitations and shortcomings remain underexplored. In this paper, through rigorous experiments and an in-depth analysis of the changes LLMs undergo through IT, we reveal various limitations of IT. In particular, we show that (1) IT fails to enhance knowledge or skills in LLMs. LoRA fine-tuning is limited to learning response initiation and style tokens, and full-parameter fine-tuning leads to knowledge degradation. (2) Copying response patterns from IT datasets derived from knowledgeable sources leads to a decline in response quality. (3) Full-parameter fine-tuning increases hallucination by inaccurately borrowing tokens from conceptually similar instances in the IT dataset for generating responses. (4) Popular methods to improve IT do not lead to performance improvements over a simple LoRA fine-tuned model. Our findings reveal that responses generated solely from pre-trained knowledge consistently outperform responses by models that learn any form of new knowledge from IT on open-source datasets. We hope the insights and challenges revealed in this paper inspire future work in related directions.",
      "authors": [],
      "categories": [
        "Computer Science"
      ],
      "published": "2024-01-01",
      "updated": "2024-01-01",
      "link": "https://www.semanticscholar.org/paper/acbce5ebf3f254188d10f6ba7de1ba716db89774",
      "relevance_score": 9.0,
      "relevance_reason": "The paper directly addresses the limitations of instruction tuning in large language models, which is relevant to researchers in machine learning, AI agents, and large language models. The methodology is described well in the abstract and the findings have potential impact in the field.",
      "author_h_indices": [
        18,
        10,
        2,
        15,
        10,
        12,
        2,
        56,
        20
      ],
      "huggingface_upvotes": null,
      "quality_score": 9.14795918367347
    },
    {
      "arxiv_id": "2504.14110",
      "title": "System of Agentic AI for the Discovery of Metal-Organic Frameworks",
      "abstract": "Generative models and machine learning promise accelerated material discovery in MOFs for CO2 capture and water harvesting but face significant challenges navigating vast chemical spaces while ensuring synthetizability. Here, we present MOFGen, a system of Agentic AI comprising interconnected agents: a large language model that proposes novel MOF compositions, a diffusion model that generates crystal structures, quantum mechanical agents that optimize and filter candidates, and synthetic-feasibility agents guided by expert rules and machine learning. Trained on all experimentally reported MOFs and computational databases, MOFGen generated hundreds of thousands of novel MOF structures and synthesizable organic linkers. Our methodology was validated through high-throughput experiments and the successful synthesis of five\"AI-dreamt\"MOFs, representing a major step toward automated synthesizable material discovery.",
      "authors": [],
      "categories": [
        "Computer Science",
        "Physics"
      ],
      "published": "2025-01-01",
      "updated": "2025-01-01",
      "link": "https://www.semanticscholar.org/paper/11ac1691fa7415da4f7727d74244c7d9b3ba6fce",
      "relevance_score": 9.0,
      "relevance_reason": "This paper directly addresses the researcher's interests in machine learning, AI agents, and large language models. The methodology described in the abstract demonstrates a novel approach with potential impact in the field of material discovery. The author's expertise in computer science and physics also adds to the credibility of the work.",
      "author_h_indices": [
        6,
        1,
        4,
        2,
        1,
        11,
        1,
        10,
        2,
        15,
        55,
        56,
        59,
        2,
        12
      ],
      "huggingface_upvotes": null,
      "quality_score": 9.145102040816328
    },
    {
      "arxiv_id": "1911.02557",
      "title": "Feedback-Based Self-Learning in Large-Scale Conversational AI Agents",
      "abstract": "Today, most of the large-scale conversational AI agents such as Alexa, Siri, or Google Assistant are built using manually annotated data to train the different components of the system including Automatic Speech Recognition (ASR), Natural Language Understanding (NLU) and Entity Resolution (ER). Typically, the accuracy of the machine learning models in these components are improved by manually transcribing and annotating data. As the scope of these systems increase to cover more scenarios and domains, manual annotation to improve the accuracy of these components becomes prohibitively costly and time consuming. In this paper, we propose a system that leverages customer/system interaction feedback signals to automate learning without any manual annotation. Users of these systems tend to modify a previous query in hopes of fixing an error in the previous turn to get the right results. These reformulations, which are often preceded by defective experiences caused by either errors in ASR, NLU, ER or the application. In some cases, users may not properly formulate their requests (e.g. providing partial title of a song), but gleaning across a wider pool of users and sessions reveals the underlying recurrent patterns. Our proposed self-learning system automatically detects the errors, generate reformulations and deploys fixes to the runtime system to correct different types of errors occurring in different components of the system. In particular, we propose leveraging an absorbing Markov Chain model as a collaborative filtering mechanism in a novel attempt to mine these patterns. We show that our approach is highly scalable, and able to learn reformulations that reduce Alexa-user errors by pooling anonymized data across millions of customers. The proposed self-learning system achieves a win-loss ratio of 11.8 and effectively reduces the defect rate by more than 30% on utterance level reformulations in our production A/B tests. To the best of our knowledge, this is the first self-learning large-scale conversational AI system in production.",
      "authors": [],
      "categories": [
        "Computer Science"
      ],
      "published": "2019-01-01",
      "updated": "2019-01-01",
      "link": "https://www.semanticscholar.org/paper/a76b5dfe741c72b507159a0af7bfeb07256262b8",
      "relevance_score": 9.0,
      "relevance_reason": "This paper is highly relevant to a researcher interested in machine learning, AI agents, and large language models. The methodology of leveraging feedback signals for self-learning in conversational AI agents is novel and has the potential for significant impact in the field.",
      "author_h_indices": [
        6,
        4,
        11,
        32
      ],
      "huggingface_upvotes": null,
      "quality_score": 9.121683673469388
    },
    {
      "arxiv_id": "2509.14546",
      "title": "Rationality Check! Benchmarking the Rationality of Large Language Models",
      "abstract": "Large language models (LLMs), a recent advance in deep learning and machine intelligence, have manifested astonishing capacities, now considered among the most promising for artificial general intelligence. With human-like capabilities, LLMs have been used to simulate humans and serve as AI assistants across many applications. As a result, great concern has arisen about whether and under what circumstances LLMs think and behave like real human agents. Rationality is among the most important concepts in assessing human behavior, both in thinking (i.e., theoretical rationality) and in taking action (i.e., practical rationality). In this work, we propose the first benchmark for evaluating the omnibus rationality of LLMs, covering a wide range of domains and LLMs. The benchmark includes an easy-to-use toolkit, extensive experimental results, and analysis that illuminates where LLMs converge and diverge from idealized human rationality. We believe the benchmark can serve as a foundational tool for both developers and users of LLMs.",
      "authors": [],
      "categories": [
        "Computer Science"
      ],
      "published": "2025-01-01",
      "updated": "2025-01-01",
      "link": "https://www.semanticscholar.org/paper/515ca2fd91e1a9eee9b2993ae69e6c23b876e872",
      "relevance_score": 9.0,
      "relevance_reason": "This paper is highly relevant to a researcher interested in machine learning, AI agents, and large language models. It proposes a benchmark for evaluating the rationality of LLMs, which aligns with the researcher's interests. The abstract suggests a strong methodology and potential impact in the field.",
      "author_h_indices": [
        7,
        2,
        5,
        10,
        33,
        2,
        4
      ],
      "huggingface_upvotes": null,
      "quality_score": 9.08265306122449
    },
    {
      "arxiv_id": "2408.06292",
      "title": "The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery",
      "abstract": "One of the grand challenges of artificial general intelligence is developing agents capable of conducting scientific research and discovering new knowledge. While frontier models have already been used as aides to human scientists, e.g. for brainstorming ideas, writing code, or prediction tasks, they still conduct only a small part of the scientific process. This paper presents the first comprehensive framework for fully automatic scientific discovery, enabling frontier large language models to perform research independently and communicate their findings. We introduce The AI Scientist, which generates novel research ideas, writes code, executes experiments, visualizes results, describes its findings by writing a full scientific paper, and then runs a simulated review process for evaluation. In principle, this process can be repeated to iteratively develop ideas in an open-ended fashion, acting like the human scientific community. We demonstrate its versatility by applying it to three distinct subfields of machine learning: diffusion modeling, transformer-based language modeling, and learning dynamics. Each idea is implemented and developed into a full paper at a cost of less than $15 per paper. To evaluate the generated papers, we design and validate an automated reviewer, which we show achieves near-human performance in evaluating paper scores. The AI Scientist can produce papers that exceed the acceptance threshold at a top machine learning conference as judged by our automated reviewer. This approach signifies the beginning of a new era in scientific discovery in machine learning: bringing the transformative benefits of AI agents to the entire research process of AI itself, and taking us closer to a world where endless affordable creativity and innovation can be unleashed on the world's most challenging problems. Our code is open-sourced at https://github.com/SakanaAI/AI-Scientist",
      "authors": [],
      "categories": [
        "Computer Science"
      ],
      "published": "2024-01-01",
      "updated": "2024-01-01",
      "link": "https://www.semanticscholar.org/paper/33161a5a9b5dcb635b5a97475e6a6209a69ada7d",
      "relevance_score": 9.0,
      "relevance_reason": "This paper is highly relevant to a researcher interested in machine learning, AI agents, and large language models. It presents a novel framework for fully automated scientific discovery using large language models, which has the potential for significant impact in the field.",
      "author_h_indices": [
        5,
        14,
        8,
        9,
        5,
        3
      ],
      "huggingface_upvotes": null,
      "quality_score": 9.06734693877551
    },
    {
      "arxiv_id": "s2:208b93a39802466785169494caa7f2a8995ea39f",
      "title": "Large Language Model-Empowered Agents for Simulating Macroeconomic Activities",
      "abstract": "The advent of the Web has brought about a paradigm shift in traditional economics, particularly in the digital economy era, enabling the precise recording and analysis of individual economic behavior. This has led to a growing emphasis on data-driven modeling in macroeconomics. In macroeconomic research, Agent-based modeling (ABM) emerged as an alternative, evolving through rule-based agents, machine learning-enhanced decision-making, and, more recently, advanced AI agents. However, the existing works are suffering from three main challenges when endowing agents with human-like decision-making, including agent heterogeneity, the influence of macroeconomic trends, and multifaceted economic factors. Large language models (LLMs) have recently gained prominence in offering autonomous human-like characteristics. Therefore, leveraging LLMs in macroeconomic simulation presents an opportunity to overcome traditional limitations. In this work, we take an early step in introducing a novel approach that leverages LLMs in macroeconomic simulation. We design prompt-engineering-driven LLM agents to exhibit human-like decision-making and adaptability in the economic environment, with the abilities of perception, reflection, and decision-making to address the abovementioned challenges. Simulation experiments on macroeconomic activities show that LLM-empowered agents can make realistic work and consumption decisions and emerge more reasonable macroeconomic phenomena than existing rule-based or AI agents. Our work demonstrates the promising potential to simulate macroeconomics based on LLM and its human-like characteristics.",
      "authors": [],
      "categories": [
        "Computer Science"
      ],
      "published": "2023-01-01",
      "updated": "2023-01-01",
      "link": "https://www.semanticscholar.org/paper/208b93a39802466785169494caa7f2a8995ea39f",
      "relevance_score": 9.0,
      "relevance_reason": "This paper is highly relevant as it directly addresses the interests in large language models, AI agents, and machine learning in the context of simulating macroeconomic activities. The methodology described in the abstract is of high quality and the potential impact of using LLMs in this field is significant.",
      "author_h_indices": [
        12,
        5,
        5,
        5
      ],
      "huggingface_upvotes": null,
      "quality_score": 9.061989795918366
    },
    {
      "arxiv_id": "2407.10022",
      "title": "AtomAgents: Alloy design and discovery through physics-aware multi-modal multi-agent artificial intelligence",
      "abstract": "The design of alloys is a multi-scale problem that requires a holistic approach that involves retrieving relevant knowledge, applying advanced computational methods, conducting experimental validations, and analyzing the results, a process that is typically reserved for human experts. Machine learning (ML) can help accelerate this process, for instance, through the use of deep surrogate models that connect structural features to material properties, or vice versa. However, existing data-driven models often target specific material objectives, offering limited flexibility to integrate out-of-domain knowledge and cannot adapt to new, unforeseen challenges. Here, we overcome these limitations by leveraging the distinct capabilities of multiple AI agents that collaborate autonomously within a dynamic environment to solve complex materials design tasks. The proposed physics-aware generative AI platform, AtomAgents, synergizes the intelligence of large language models (LLM) the dynamic collaboration among AI agents with expertise in various domains, including knowledge retrieval, multi-modal data integration, physics-based simulations, and comprehensive results analysis across modalities that includes numerical data and images of physical simulation results. The concerted effort of the multi-agent system allows for addressing complex materials design problems, as demonstrated by examples that include autonomously designing metallic alloys with enhanced properties compared to their pure counterparts. Our results enable accurate prediction of key characteristics across alloys and highlight the crucial role of solid solution alloying to steer the development of advanced metallic alloys. Our framework enhances the efficiency of complex multi-objective design tasks and opens new avenues in fields such as biomedical materials engineering, renewable energy, and environmental sustainability.",
      "authors": [],
      "categories": [
        "Computer Science",
        "Physics"
      ],
      "published": "2024-01-01",
      "updated": "2024-01-01",
      "link": "https://www.semanticscholar.org/paper/741d039aba804db2e2600fc7be7a1b8e303aec49",
      "relevance_score": 9.0,
      "relevance_reason": "This paper is highly relevant to a researcher interested in machine learning, AI agents, and large language models as it describes a novel approach using multiple AI agents to address complex material design problems.",
      "author_h_indices": [
        6,
        7
      ],
      "huggingface_upvotes": null,
      "quality_score": 9.05969387755102
    },
    {
      "arxiv_id": "2503.22164",
      "title": "PharmAgents: Building a Virtual Pharma with Large Language Model Agents",
      "abstract": "The discovery of novel small molecule drugs remains a critical scientific challenge with far-reaching implications for treating diseases and advancing human health. Traditional drug development--especially for small molecule therapeutics--is a highly complex, resource-intensive, and time-consuming process that requires multidisciplinary collaboration. Recent breakthroughs in artificial intelligence (AI), particularly the rise of large language models (LLMs), present a transformative opportunity to streamline and accelerate this process. In this paper, we introduce PharmAgents, a virtual pharmaceutical ecosystem driven by LLM-based multi-agent collaboration. PharmAgents simulates the full drug discovery workflow--from target discovery to preclinical evaluation--by integrating explainable, LLM-driven agents equipped with specialized machine learning models and computational tools. Through structured knowledge exchange and automated optimization, PharmAgents identifies potential therapeutic targets, discovers promising lead compounds, enhances binding affinity and key molecular properties, and performs in silico analyses of toxicity and synthetic feasibility. Additionally, the system supports interpretability, agent interaction, and self-evolvement, enabling it to refine future drug designs based on prior experience. By showcasing the potential of LLM-powered multi-agent systems in drug discovery, this work establishes a new paradigm for autonomous, explainable, and scalable pharmaceutical research, with future extensions toward comprehensive drug lifecycle management.",
      "authors": [],
      "categories": [
        "Computer Science",
        "Biology"
      ],
      "published": "2025-01-01",
      "updated": "2025-01-01",
      "link": "https://www.semanticscholar.org/paper/46e921cb6fba3423e48fa894afa9b0b47bf934d6",
      "relevance_score": 9.0,
      "relevance_reason": "This paper is highly relevant to a researcher interested in machine learning, AI agents, and large language models as it specifically focuses on utilizing LLM-based multi-agent collaboration in the pharmaceutical industry, showcasing the potential impact and novelty of the work.",
      "author_h_indices": [
        6,
        6,
        2,
        3,
        9,
        3,
        12
      ],
      "huggingface_upvotes": null,
      "quality_score": 9.053790087463558
    },
    {
      "arxiv_id": "s2:6bd18e556a1884ef5681867d44fd044dab39d424",
      "title": "Fine Tuning LLMs vs Non-Generative Machine Learning Models: A Comparative Study of Malware Detection",
      "abstract": ": The emergence of Generative AI has provided various scenarios where Large Language Models can be used to replace older technologies. Cyber-security industry has been an early adopter of these technologies, but in particular for scenarios that involved security operation centers, support or cyber attack visibility. This paper aims to compare how well Large Language Models behave against traditional machine learning models for malware detection wrt. various constrains that apply to a security product such as inference time, memory footprint, detection and false positive rate. In this paper we have fine tuned 3 open source models (LLama2-13B, Mistral, Mixtral) and compared them with 18 classical machine learning models (feed forward neural networks, SVMs, etc) using more than 135,000 benign and malicious binary samples. The goal was to identify scenarios/cases where large language models are suited for the task of malware detection.",
      "authors": [],
      "categories": [
        "Computer Science"
      ],
      "published": "2025-01-01",
      "updated": "2025-01-01",
      "link": "https://www.semanticscholar.org/paper/6bd18e556a1884ef5681867d44fd044dab39d424",
      "relevance_score": 9.0,
      "relevance_reason": "This paper is highly relevant to researchers interested in machine learning, AI agents, and large language models as it directly compares LLMs with traditional machine learning models for malware detection. The methodology is well-described with the use of open source models and a large dataset, and the potential impact of the work in the cybersecurity industry is significant.",
      "author_h_indices": [
        4,
        2,
        11
      ],
      "huggingface_upvotes": null,
      "quality_score": 9.052040816326532
    },
    {
      "arxiv_id": "2408.14033",
      "title": "MLR-Copilot: Autonomous Machine Learning Research based on Large Language Models Agents",
      "abstract": "Autonomous machine learning research has gained significant attention recently. We present MLR-COPILOT, an autonomous Machine Learning Research framework powered by large language model agents. The system is designed to enhance ML research productivity through automatic generation and implementation of research ideas within constraints. Our work was released in August 2024 (concurrent to AI-Scientist) and has gained notable recognition from leading projects. We further enhance our ideation with training afterwards. The framework consists of three stages: idea generation, experiment implementation, and code execution. First, existing research papers are used to generate feasible ideas and experiment plans with IdeaAgent, powered by an RL-tuned LLM. Next, ExperimentAgent leverages retrieved prototype code to convert plans into executable code with optionally retrieved candidate models and data from HuggingFace. In the final stage, ExperimentAgent runs experiments, and allows subsequent iterations of debugging and human feedback for a better chance of success with executable outcomes. We evaluate our framework on five machine learning research tasks. Experiment results demonstrate the potential of our framework to facilitate ML research progress and innovation.",
      "authors": [],
      "categories": [
        "Computer Science"
      ],
      "published": "2024-01-01",
      "updated": "2024-01-01",
      "link": "https://www.semanticscholar.org/paper/d0cd8b45949b959c316a3ed75a4683d0a70b1aa9",
      "relevance_score": 9.0,
      "relevance_reason": "This paper is highly relevant to a researcher interested in machine learning, AI agents, and large language models. The authors present a novel framework for autonomous machine learning research, leveraging large language model agents. The methodology described in the abstract is of high quality, and the potential impact of the work is significant. The paper aligns with current interests and trends in the field.",
      "author_h_indices": [
        6,
        2,
        13,
        1,
        5
      ],
      "huggingface_upvotes": null,
      "quality_score": 9.049591836734693
    },
    {
      "arxiv_id": "2501.07278",
      "title": "Lifelong Learning of Large Language Model based Agents: A Roadmap",
      "abstract": "Lifelong learning, also known as continual or incremental learning, is a crucial component for advancing Artificial General Intelligence (AGI) by enabling systems to continuously adapt in dynamic environments. While large language models (LLMs) have demonstrated impressive capabilities in natural language processing, existing LLM agents are typically designed for static systems and lack the ability to adapt over time in response to new challenges. This survey is the first to systematically summarize the potential techniques for incorporating lifelong learning into LLM-based agents. We categorize the core components of these agents into three modules: the perception module for multimodal input integration, the memory module for storing and retrieving evolving knowledge, and the action module for grounded interactions with the dynamic environment. We highlight how these pillars collectively enable continuous adaptation, mitigate catastrophic forgetting, and improve long-term performance. This survey provides a roadmap for researchers and practitioners working to develop lifelong learning capabilities in LLM agents, offering insights into emerging trends, evaluation metrics, and application scenarios. Relevant literature and resources are available at at https://github.com/qianlimalab/ awesome-lifelong-llm-agent.",
      "authors": [],
      "categories": [
        "Computer Science",
        "Medicine"
      ],
      "published": "2025-01-01",
      "updated": "2025-01-01",
      "link": "https://www.semanticscholar.org/paper/76aebf01bdfeaf743ac83ac231384a861f7b69ca",
      "relevance_score": 9.0,
      "relevance_reason": "This paper is highly relevant to a researcher interested in machine learning, AI agents, and large language models as it specifically focuses on the integration of lifelong learning techniques into LLM-based agents, offering a roadmap for researchers in the field.",
      "author_h_indices": [
        11,
        2,
        3,
        2,
        5,
        4,
        5,
        8
      ],
      "huggingface_upvotes": null,
      "quality_score": 9.045918367346939
    },
    {
      "arxiv_id": "s2:56cf2311379429120ba6d8fc6de5d799c8a9da38",
      "title": "Digital Cardiovascular Twins, AI Agents, and Sensor Data: A Narrative Review from System Architecture to Proactive Heart Health",
      "abstract": "Cardiovascular disease remains the world\u2019s leading cause of mortality, yet everyday care still relies on episodic, symptom-driven interventions that detect ischemia, arrhythmias, and remodeling only after tissue damage has begun, limiting the effectiveness of therapy. A narrative review synthesized 183 studies published between 2016 and 2025 that were located through PubMed, MDPI, Scopus, IEEE Xplore, and Web of Science. This review examines CVD diagnostics using innovative technologies such as digital cardiovascular twins, which involve the collection of data from wearable IoT devices (electrocardiography (ECG), photoplethysmography (PPG), and mechanocardiography), clinical records, laboratory biomarkers, and genetic markers, as well as their integration with artificial intelligence (AI), including machine learning and deep learning, graph and transformer networks for interpreting multi-dimensional data streams and creating prognostic models, as well as generative AI, medical large language models (LLMs), and autonomous agents for decision support, personalized alerts, and treatment scenario modeling, and with cloud and edge computing for data processing. This multi-layered architecture enables the detection of silent pathologies long before clinical manifestations, transforming continuous observations into actionable recommendations and shifting cardiology from reactive treatment to predictive and preventive care. Evidence converges on four layers: sensors streaming multimodal clinical and environmental data; hybrid analytics that integrate hemodynamic models with deep-, graph- and transformer learning while Bayesian and Kalman filters manage uncertainty; decision support delivered by domain-tuned medical LLMs and autonomous agents; and prospective simulations that trial pacing or pharmacotherapy before bedside use, closing the prediction-intervention loop. This stack flags silent pathology weeks in advance and steers proactive personalized prevention. It also lays the groundwork for software-as-a-medical-device ecosystems and new regulatory guidance for trustworthy AI-enabled cardiovascular care.",
      "authors": [],
      "categories": [
        "Medicine"
      ],
      "published": "2025-01-01",
      "updated": "2025-01-01",
      "link": "https://www.semanticscholar.org/paper/56cf2311379429120ba6d8fc6de5d799c8a9da38",
      "relevance_score": 9.0,
      "relevance_reason": "This paper is highly relevant to researchers interested in machine learning, AI agents, and large language models as it discusses the use of innovative technologies such as digital cardiovascular twins, AI integration, and the potential impact on proactive heart health. The methodology described in the abstract is of high quality and the potential impact of the work is significant in the field.",
      "author_h_indices": [
        5,
        5,
        4,
        4,
        5,
        2,
        1,
        1
      ],
      "huggingface_upvotes": null,
      "quality_score": 9.030994897959184
    },
    {
      "arxiv_id": "2506.12822",
      "title": "Enhancing Rating-Based Reinforcement Learning to Effectively Leverage Feedback from Large Vision-Language Models",
      "abstract": "Designing effective reward functions remains a fundamental challenge in reinforcement learning (RL), as it often requires extensive human effort and domain expertise. While RL from human feedback has been successful in aligning agents with human intent, acquiring high-quality feedback is costly and labor-intensive, limiting its scalability. Recent advancements in foundation models present a promising alternative--leveraging AI-generated feedback to reduce reliance on human supervision in reward learning. Building on this paradigm, we introduce ERL-VLM, an enhanced rating-based RL method that effectively learns reward functions from AI feedback. Unlike prior methods that rely on pairwise comparisons, ERL-VLM queries large vision-language models (VLMs) for absolute ratings of individual trajectories, enabling more expressive feedback and improved sample efficiency. Additionally, we propose key enhancements to rating-based RL, addressing instability issues caused by data imbalance and noisy labels. Through extensive experiments across both low-level and high-level control tasks, we demonstrate that ERL-VLM significantly outperforms existing VLM-based reward generation methods. Our results demonstrate the potential of AI feedback for scaling RL with minimal human intervention, paving the way for more autonomous and efficient reward learning.",
      "authors": [],
      "categories": [
        "Computer Science"
      ],
      "published": "2025-01-01",
      "updated": "2025-01-01",
      "link": "https://www.semanticscholar.org/paper/8dccf45aa7b6d3e7ef8fe762751cb35c86778141",
      "relevance_score": 9.0,
      "relevance_reason": "This paper directly addresses the interests of the researcher by discussing machine learning, AI agents, and large language models. The methodology described in the abstract appears to be of high quality, and the potential impact of the work on scaling reinforcement learning with minimal human intervention is significant.",
      "author_h_indices": [
        10,
        3,
        1,
        1,
        1,
        1
      ],
      "huggingface_upvotes": null,
      "quality_score": 9.026020408163266
    },
    {
      "arxiv_id": "2502.18652",
      "title": "Independent Mobility GPT (IDM-GPT): A Self-Supervised Multi-Agent Large Language Model Framework for Customized Traffic Mobility Analysis Using Machine Learning Models",
      "abstract": "With the urbanization process, an increasing number of sensors are being deployed in transportation systems, leading to an explosion of big data. To harness the power of this vast transportation data, various machine learning (ML) and artificial intelligence (AI) methods have been introduced to address numerous transportation challenges. However, these methods often require significant investment in data collection, processing, storage, and the employment of professionals with expertise in transportation and ML. Additionally, privacy issues are a major concern when processing data for real-world traffic control and management. To address these challenges, the research team proposes an innovative Multi-agent framework named Independent Mobility GPT (IDM-GPT) based on large language models (LLMs) for customized traffic analysis, management suggestions, and privacy preservation. IDM-GPT efficiently connects users, transportation databases, and ML models economically. IDM-GPT trains, customizes, and applies various LLM-based AI agents for multiple functions, including user query comprehension, prompts optimization, data analysis, model selection, and performance evaluation and enhancement. With IDM-GPT, users without any background in transportation or ML can efficiently and intuitively obtain data analysis and customized suggestions in near real-time based on their questions. Experimental results demonstrate that IDM-GPT delivers satisfactory performance across multiple traffic-related tasks, providing comprehensive and actionable insights that support effective traffic management and urban mobility improvement.",
      "authors": [],
      "categories": [
        "Computer Science"
      ],
      "published": "2025-01-01",
      "updated": "2025-01-01",
      "link": "https://www.semanticscholar.org/paper/884635edfd3650b0d525e52f4af507a313c24fd2",
      "relevance_score": 9.0,
      "relevance_reason": "This paper is highly relevant as it focuses on machine learning, AI agents, and large language models in the context of traffic mobility analysis. The methodology described in the abstract appears to be of high quality, and the potential impact of the work in addressing transportation challenges is significant.",
      "author_h_indices": [
        3,
        1,
        1,
        3,
        2
      ],
      "huggingface_upvotes": null,
      "quality_score": 9.018367346938776
    }
  ]
}