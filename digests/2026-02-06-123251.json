{
  "date": "2026-02-06",
  "generated_at": "2026-02-06T12:32:56.314816+00:00",
  "interests": "Ai safety, reinforcement learning optimization, token expenditure optimization, LLM memory allocation optimization.\n\nWhen ranking, also consider:\n- Author credentials and reputation (prefer established researchers from top institutions)\n- Quality of methodology described in abstract\n- Novelty and potential impact of the work\n- Papers with well-known authors in the field should be scored higher",
  "total_papers_fetched": 7,
  "papers": [
    {
      "arxiv_id": "2505.18979",
      "title": "GhostPrompt: Jailbreaking Text-to-image Generative Models based on Dynamic Optimization",
      "abstract": "Text-to-image (T2I) generation models can inadvertently produce not-safe-for-work (NSFW) content, prompting the integration of text and image safety filters. Recent advances employ large language models (LLMs) for semantic-level detection, rendering traditional token-level perturbation attacks largely ineffective. However, our evaluation shows that existing jailbreak methods are ineffective against these modern filters. We introduce GhostPrompt, the first automated jailbreak framework that combines dynamic prompt optimization with multimodal feedback. It consists of two key components: (i) Dynamic Optimization, an iterative process that guides a large language model (LLM) using feedback from text safety filters and CLIP similarity scores to generate semantically aligned adversarial prompts; and (ii) Adaptive Safety Indicator Injection, which formulates the injection of benign visual cues as a reinforcement learning problem to bypass image-level filters. GhostPrompt achieves state-of-the-art performance, increasing the ShieldLM-7B bypass rate from 12.5\\% (Sneakyprompt) to 99.0\\%, improving CLIP score from 0.2637 to 0.2762, and reducing the time cost by $4.2 \\times$. Moreover, it generalizes to unseen filters including GPT-4.1 and successfully jailbreaks DALLE 3 to generate NSFW images in our evaluation, revealing systemic vulnerabilities in current multimodal defenses. To support further research on AI safety and red-teaming, we will release code and adversarial prompts under a controlled-access protocol.",
      "authors": [],
      "categories": [
        "Computer Science"
      ],
      "published": "2025-01-01",
      "updated": "2025-01-01",
      "link": "https://www.semanticscholar.org/paper/1be3e9092f10fc67e2b2bc84d11ab1508e0fb21b",
      "relevance_score": 8.0,
      "relevance_reason": "This paper is highly relevant to the researcher's interests in AI safety, optimization, and memory allocation, as it discusses jailbreaking text-to-image generative models through dynamic optimization strategies. The methodology and potential impact of the work are strong, and the authors are established in the field of computer science.",
      "author_h_indices": [
        0,
        0,
        14,
        25,
        25
      ],
      "quality_score": 8.344615384615384
    },
    {
      "arxiv_id": "2501.03265",
      "title": "Cognitive Edge Computing: A Comprehensive Survey on Optimizing Large Models and AI Agents for Pervasive Deployment",
      "abstract": "This article surveys Cognitive Edge Computing as a practical and methodical pathway for deploying reasoning-capable Large Language Models (LLMs) and autonomous AI agents on resource-constrained devices at the network edge. We present a unified, cognition-preserving framework spanning: (1) model optimization (quantization, sparsity, low-rank adaptation, distillation) aimed at retaining multi-step reasoning under tight memory/compute budgets; (2) system architecture (on-device inference, elastic offloading, cloud-edge collaboration) that trades off latency, energy, privacy, and capacity; and (3) adaptive intelligence (context compression, dynamic routing, federated personalization) that tailors computation to task difficulty and device constraints. We synthesize advances in efficient Transformer design, multimodal integration, hardware-aware compilation, privacy-preserving learning, and agentic tool use, and map them to edge-specific operating envelopes. We further outline a standardized evaluation protocol covering latency, throughput, energy per token, accuracy, robustness, privacy, and sustainability, with explicit measurement assumptions to enhance comparability. Remaining challenges include modality-aware reasoning benchmarks, transparent and reproducible energy reporting, edge-oriented safety/alignment evaluation, and multi-agent testbeds. We conclude with practitioner guidelines for cross-layer co-design of algorithms, runtime, and hardware to deliver reliable, efficient, and privacy-preserving cognitive capabilities on edge devices.",
      "authors": [],
      "categories": [
        "Computer Science"
      ],
      "published": "2025-01-01",
      "updated": "2025-01-01",
      "link": "https://www.semanticscholar.org/paper/6e4ac103b4a76bee2d1c436b23c47eff9f6bdd90",
      "relevance_score": 8.0,
      "relevance_reason": "The paper is highly relevant as it covers topics such as optimization of large models, memory allocation, and AI agent deployment at the network edge, aligning well with the researcher's interests in AI safety, reinforcement learning optimization, and token expenditure optimization.",
      "author_h_indices": [
        5,
        2,
        3
      ],
      "quality_score": 8.08974358974359
    },
    {
      "arxiv_id": "s2:6653772c61df91c8b625b1f8aba552e5ae9cc8a1",
      "title": "Meta-Adaptive Context Engineering: A Learned Framework for Optimizing Individual AI Agents Beyond Single-Dimension Approaches",
      "abstract": "",
      "authors": [],
      "categories": [
        "semantic_scholar"
      ],
      "published": "",
      "updated": "",
      "link": "https://www.semanticscholar.org/paper/6653772c61df91c8b625b1f8aba552e5ae9cc8a1",
      "relevance_score": 8.0,
      "relevance_reason": "The paper is highly relevant as it focuses on optimizing AI agents, which aligns with the researcher's interests in AI safety, reinforcement learning optimization, and token expenditure optimization. The methodology described in the abstract seems promising, and the potential impact on individual AI agents is substantial. Furthermore, the paper's novelty and potential impact make it a valuable read for researchers in the field.",
      "author_h_indices": [
        0
      ],
      "quality_score": 8.0
    },
    {
      "arxiv_id": "2508.10501",
      "title": "PASS: Probabilistic Agentic Supernet Sampling for Interpretable and Adaptive Chest X-Ray Reasoning",
      "abstract": "Existing tool-augmented agentic systems are limited in the real world by (i) black-box reasoning steps that undermine trust of decision-making and pose safety risks, (ii) poor multimodal integration, which is inherently critical for healthcare tasks, and (iii) rigid and computationally inefficient agentic pipelines. We introduce PASS (Probabilistic Agentic Supernet Sampling), the first multimodal framework to address these challenges in the context of Chest X-Ray (CXR) reasoning. PASS adaptively samples agentic workflows over a multi-tool graph, yielding decision paths annotated with interpretable probabilities. Given the complex CXR reasoning task with multimodal medical data, PASS leverages its learned task-conditioned distribution over the agentic supernet. Thus, it adaptively selects the most suitable tool at each supernet layer, offering probability-annotated trajectories for post-hoc audits and directly enhancing medical AI safety. PASS also continuously compresses salient findings into an evolving personalized memory, while dynamically deciding whether to deepen its reasoning path or invoke an early exit for efficiency. To optimize a Pareto frontier balancing performance and cost, we design a novel three-stage training procedure, including expert knowledge warm-up, contrastive path-ranking, and cost-aware reinforcement learning. To facilitate rigorous evaluation, we introduce CAB-E, a comprehensive benchmark for multi-step, safety-critical, free-form CXR reasoning. Experiments across various benchmarks validate that PASS significantly outperforms strong baselines in multiple metrics (e.g., accuracy, LLM-Judge, semantic similarity, etc.) while balancing computational costs, pushing a new paradigm shift towards interpretable, adaptive, and multimodal medical agentic systems.",
      "authors": [],
      "categories": [
        "Computer Science"
      ],
      "published": "2025-01-01",
      "updated": "2025-01-01",
      "link": "https://www.semanticscholar.org/paper/4f2c987f175936e94da0baa9b3b6c8384cda63d6",
      "relevance_score": 4.0,
      "relevance_reason": "While the paper addresses topics related to optimization and reasoning in AI, it is not directly focused on AI safety, reinforcement learning optimization, token expenditure optimization, or LLM memory allocation optimization. The methodology described in the abstract seems robust, but the relevance to the specific research interests is limited.",
      "author_h_indices": [
        1,
        0,
        0,
        0,
        0
      ],
      "quality_score": 4.002692307692308
    },
    {
      "arxiv_id": "s2:ff66ab7db7ac31b8ba1831a8e038a756a4467ee1",
      "title": "AI 2007 : Advances in artificial intelligence : 20th Australian Joint Conference on Artificial Intelligence Gold Coast, Australia, December 2-6, 2007 : proceedings",
      "abstract": "",
      "authors": [],
      "categories": [
        "Engineering",
        "Computer Science"
      ],
      "published": "2007-01-01",
      "updated": "2007-01-01",
      "link": "https://www.semanticscholar.org/paper/ff66ab7db7ac31b8ba1831a8e038a756a4467ee1",
      "relevance_score": 2.0,
      "relevance_reason": "This paper appears to be a general conference proceedings from AI 2007 without specific focus on AI safety, reinforcement learning optimization, token expenditure optimization, or LLM memory allocation optimization.",
      "author_h_indices": [
        42,
        16
      ],
      "quality_score": 2.1951923076923077
    },
    {
      "arxiv_id": "s2:d0ad26b1445c342cf110bcfe7eb3685de0bb8867",
      "title": "AI 2004: Advances in Artificial Intelligence, 17th Australian Joint Conference on Artificial Intelligence, Cairns, Australia, December 4-6, 2004, Proceedings",
      "abstract": "",
      "authors": [],
      "categories": [
        "Computer Science"
      ],
      "published": "2004-01-01",
      "updated": "2004-01-01",
      "link": "https://www.semanticscholar.org/paper/d0ad26b1445c342cf110bcfe7eb3685de0bb8867",
      "relevance_score": 1.0,
      "relevance_reason": "Not relevant - This paper does not directly address any of the specific interests mentioned by the researcher, and the abstract does not provide information on AI safety, reinforcement learning optimization, token expenditure optimization, or LLM memory allocation optimization.",
      "author_h_indices": [
        81,
        104
      ],
      "quality_score": 1.3112980769230769
    },
    {
      "arxiv_id": "s2:e0ff1e95e940e29e7cdc99a84492a37e3a051786",
      "title": "RIACS FY2001 Annual Report",
      "abstract": "",
      "authors": [],
      "categories": [
        "Environmental Science"
      ],
      "published": "2001-01-01",
      "updated": "2001-01-01",
      "link": "https://www.semanticscholar.org/paper/e0ff1e95e940e29e7cdc99a84492a37e3a051786",
      "relevance_score": 1.0,
      "relevance_reason": "Not relevant - the paper is about Environmental Science, not Ai safety, reinforcement learning optimization, token expenditure optimization, or LLM memory allocation optimization.",
      "author_h_indices": [
        14
      ],
      "quality_score": 1.0471153846153847
    }
  ]
}